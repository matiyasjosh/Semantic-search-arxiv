{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594f046c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install arxiv pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f44b4b7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import arxiv\n",
    "import pandas as pd\n",
    "\n",
    "# Define your query and settings\n",
    "search = arxiv.Search(\n",
    "    query=\"cat:cs.AI\",  # Change to cs.CV or any other category\n",
    "    max_results=100, # Reduced max_results to a smaller number\n",
    "    sort_by=arxiv.SortCriterion.SubmittedDate\n",
    ")\n",
    "\n",
    "client = arxiv.Client()\n",
    "\n",
    "# Collect metadata\n",
    "results = []\n",
    "for result in client.results(search):\n",
    "    results.append({\n",
    "        \"Title\": result.title,\n",
    "        \"Authors\": \", \".join([author.name for author in result.authors]),\n",
    "        \"Date\": result.published.date(),\n",
    "        \"Summary\": result.summary.strip().replace(\"\\n\", \" \"),\n",
    "        \"pdf_url\": result.pdf_url\n",
    "    })\n",
    "\n",
    "    print\n",
    "\n",
    "# Display as a table\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(\"data.csv\", index=False)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fdf77c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#code for downloading function\n",
    "import os, requests\n",
    "\n",
    "os.makedirs(\"downloads\", exist_ok=True)\n",
    "\n",
    "for result in results:\n",
    "    title = result[\"Title\"].replace(' ', '_').replace('/','_')\n",
    "    pdf_url = result[\"pdf_url\"]\n",
    "    response = requests.get(pdf_url)\n",
    "\n",
    "\n",
    "    if response.status_code == 200:\n",
    "      with open(f\"downloads/{title}.pdf\", \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "    else:\n",
    "      print(f\"Failed to download {title}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e92495",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#extracting content from the fetched documents\n",
    "import fitz\n",
    "\n",
    "def extract_text(pdf_path):\n",
    "  text = \"\"\n",
    "  doc = fitz.open(pdf_path)\n",
    "\n",
    "  for page in doc:\n",
    "    text += page.get_text()\n",
    "\n",
    "  return text\n",
    "\n",
    "file_paths = [...] # add filepath of the downloaded doucments\n",
    "\n",
    "docs_content = []\n",
    "\n",
    "for file_path in file_paths:\n",
    "  docs_content.append(extract_text(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aed2714",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# extracting chunks\n",
    "def chunk_doucuments(docs, chunk_size=1):\n",
    "  chunks = []\n",
    "  for doc in docs:\n",
    "    paragraphs = [p.strip() for p in doc.split(\"\\n\") if p.strip()]\n",
    "    chunks.extend(paragraphs)\n",
    "\n",
    "  return chunks\n",
    "\n",
    "abstracts = [result['Summary'] for result in results]\n",
    "chunks = chunk_doucuments(abstracts)\n",
    "\n",
    "print(chunks, f\"\\n{len(chunks)}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
